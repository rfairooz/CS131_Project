# Signal Vision Project

## TechStack
+ AlexNet - CNN
+ Python
+ Tensorflow
+ Jetson Nano 2.0 gb/4.0 gb
+ Logitech Webcam

## Problem

People with hearing disabilities often need to rely on another person to learn and communicate in sign language. This problem pertains mostly to education and healthcare fields. Majority of technologies are not tailored towards people who are non typical users. We believe it would be easier and more fulfilling for people with disabilities to learn independently with the use of AI. 

## Solution

An AI driven sign language application, SignalVision, whcih will detect hand gestures and output the message and/or symbol for the user. Our model will be trained on image sets of each letter and their corresponding signs to recognize the motions with reliable confidence and accuracy. 

## Project Proposals and Milestones

Below are the phases of the projects describing what technology, devices and methods we used to build this product. 

+ [Phase 1]()
+ [Phase 2]()
+ [Final Presentation]()

